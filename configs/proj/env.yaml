# @package _global_
# ! Usage
# These variables are meant to be FIXED across ALL experiments.
# Note that these variables are not influencing the names of temp files.
defaults:
  - override /hydra/hydra_logging@_group_: none # Disable Hydra logging
  - override /hydra/job_logging@_group_: none # Disable Hydra logging
_user_cfg_lookup:
  root:
    code_root: /root/ # For small and SHARED storage, e.g. code
    data_root: /root/ # For small and SHARED storage, e.g. data download files
    scratch: /root/autodl-tmp # For checkpoints
    init_commands: [ 'source /etc/network_turbo', 'export CUDA_VISIBLE_DEVICES=0' ]
#    init_commands: [ 'module load cuda/${..cuda_version}' ]
user_cfg: ${oc.select:_user_cfg_lookup.${replace_dot_by_underscore:${oc.env:USER}},null}

env:
  # @ You can store your own private configs such as api_keys in an external file outside
  # @ this git folder to prevent leakage of the private api_keys to public.
  private_cfg_file: ${.path.code_root}Utils/configs/private.yaml
  proj:
    name: MPLM
    conda_env: ${oc.select:user_cfg.conda_env,base}
    cuda_version: ${oc.select:user_cfg.cuda_version,11.0}
    init_commands: ${oc.select:user_cfg.init_commands,null}
  path: # @ path end with /, file end without /
    home: ${oc.env:HOME}/
    scratch: ${oc.select:user_cfg.scratch,${oc.env:SCRATCH, 'scratch'}}/ # Use project root as default
    code_root: ${oc.select:user_cfg.code_root,${.scratch}}/ # Use project root as default
    data_root: ${oc.select:user_cfg.data_root,${.scratch}}/ # Use project root as default
    project: ${.scratch}${..proj.name}/
    temp_dir: temp/
    slurm_tmp_dir: ${oc.env:SLURM_TMPDIR, 'temp'}/ #
    out_dir: output/ #
    raw_data_dir: ${.data_root}data/
    temp_data_dir: ${.temp_dir}data/
    hf_cache: ${.scratch}.hf_cache/checkpoints/
    hf_local: ${.scratch}.hf_cache/models/
  vars: # @ To be initialized by os.env
    cuda_home: ${oc.select:user_cfg.cuda_home,'/usr/local/cuda/'}
    wandb_dir: ${..path.slurm_tmp_dir}wandb/
    wandb_cache_dir: ${..path.slurm_tmp_dir}wandb/cache/
    wandb_entity: jzshared
    wandb_proj: ${oc.select:wandb_proj,MPLM}
    huggingface_hub_cache: ${..path.hf_cache}
    # Private vars


    # Project aliases
  aliases: # @ For shell convenience
    _ds_cmd_prefix: CUDA_VISIBLE_DEVICES=0 torchrun --nnodes 1 --nproc_per_node 1 --master_port=47929 src/scripts/run_gllm_sft.py use_deepspeed=true use_fp16=true use_bf16=true model=gllm
    train: ${._ds_cmd_prefix}
  #    train:
  sweep_debug_settings:
    wandb_debug_project: MPLM-Debug
    debug_sweep_settings:
      exp:
        values:
          - cpu_debug