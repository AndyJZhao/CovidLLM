{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daebc414",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "current_folder = str(globals()['_dh'][0])\n",
    "root_path = current_folder.split('src/')[0]\n",
    "os.chdir(root_path)\n",
    "sys.path.append(root_path + 'src')\n",
    "\n",
    "from utils.basics import init_env_variables, print_important_cfg, time_logger\n",
    "from tqdm import tqdm\n",
    "from math import ceil\n",
    "\n",
    "init_env_variables()\n",
    "\n",
    "from utils.pkg.distributed import initialize_deepspeed, initialize_distributed\n",
    "from utils.project.exp import init_experiment\n",
    "import logging\n",
    "import hydra\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "logging.getLogger(\"transformers\").setLevel(logging.WARNING)\n",
    "logging.getLogger(\"transformers.tokenization_utils\").setLevel(logging.ERROR)\n",
    "os.environ['TOKENIZERS_PARALLELISM'] = 'false'\n",
    "\n",
    "from covid_llm.agent import DeepSpeedAgent, Agent\n",
    "from covid_llm.instruction_dataset import InstructionDataset, load_sft_dataset\n",
    "from covid_llm.model import CovidLLM\n",
    "from utils.data.covid_data import CovidData\n",
    "import torch as th\n",
    "\n",
    "from covid_llm.metrics import calc_prediction_class_distribution\n",
    "\n",
    "from hydra import compose, initialize\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "initialize(config_path=f'../../configs', version_base=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ad3b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = compose(config_name=\"main\", overrides=['seed=2023', 'splits_type=sta_aug_splits', 'target=t1', \n",
    "                                               'total_steps=1301', 'use_cont_fields=True',\n",
    "                                               'use_deepspeed=False', 'use_trends=False',\n",
    "                                               'use_wandb=False','wandb.name=zero_shot_t1_simple_prompt_decrease',\n",
    "                                               'data_file=processed_v5_3_BA1.pkl', 'use_variant_prompt=True',\n",
    "                                               'eval_freq=1300', 'save_model=True'])\n",
    "print(OmegaConf.to_yaml(cfg))\n",
    "cfg, logger = init_experiment(cfg)\n",
    "cfg.use_bf16 = th.cuda.is_bf16_supported() and cfg.use_bf16\n",
    "initialize_deepspeed(cfg)\n",
    "data = CovidData(cfg=cfg)\n",
    "model = CovidLLM(cfg, data, logger)\n",
    "\n",
    "model_path = '/home/hy235/zy/llm/CovidLLM4_5/output/None/' + \\\n",
    "'CovidLLM/nmwnlvqy-t1-sta_aug_splits-True-False-val_mse/checkpoints/final_model/pytorch_model.pt'\n",
    "\n",
    "pretrained_dict=th.load(model_path)\n",
    "model_dict=model.state_dict()\n",
    "pretrained_dict = {k: v for k, v in pretrained_dict.items() if k in model_dict}\n",
    "model_dict.update(pretrained_dict)\n",
    "model.load_state_dict(model_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a64aa56",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.tokenizer.from_pretrained('/home/hy235/zy/llm/CovidLLM4_5/output/None/CovidLLM/nmwnlvqy-t1-sta_aug_splits-True-False-val_mse/checkpoints/final_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "432acd6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "initialize_distributed(cfg, logger)\n",
    "batch_size = cfg.world_size * cfg.ds['train_micro_batch_size_per_gpu']\n",
    "variant_dataset = InstructionDataset(data, cfg, cfg.mode, use_variant_prompt=True)\n",
    "variant_ids = data.variant_splits\n",
    "_, variant_iter, _ = load_sft_dataset(\n",
    "            cfg,\n",
    "            full_dataset=variant_dataset, split_ids=variant_ids,\n",
    "            batch_size=cfg.inf_batch_size,\n",
    "            split='test', world_size=cfg.world_size, rank=cfg.local_rank\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d467a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "th.cuda.set_device(4)\n",
    "model.init_rank(cfg)\n",
    "model.device = 'cpu'\n",
    "model.to(model.device)\n",
    "for batch in variant_iter:\n",
    "    node_ids, prompt_tree_lol, conversation_list = batch\n",
    "    batch = np.array(node_ids).astype(np.float32), prompt_tree_lol, conversation_list\n",
    "    print(node_ids, prompt_tree_lol, conversation_list)\n",
    "    results = model.forward(batch)\n",
    "    print(results)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f5e278",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
